{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrY+5BixuMjkOCln0XE8pr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a learning notebook. The contents in this notebook are taken from various sources namely documentation"
      ],
      "metadata": {
        "id": "fsdh8iH1DgeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "RF4e_kSeGQtv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is similar to numpy arrays."
      ],
      "metadata": {
        "id": "wbSvt7wEGXpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensors  \n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along in this quick API walkthrough."
      ],
      "metadata": {
        "id": "gQ23hOpNCva-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple ways of creating a tensor\n",
        "\n",
        "x = torch.empty(3, 4)\n",
        "print(type(x))\n",
        "print(x)\n",
        "\n",
        "zeros = torch.zeros(2, 3)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(2, 3)\n",
        "print(ones)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E72mMq-cq56e",
        "outputId": "03bcd8a9-dda6-47e8-db79-9dc7f9b6d662"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dtypes in tensors\n",
        "Available data types include:\n",
        "\n",
        "- torch.bool\n",
        "- torch.int8\n",
        "- torch.uint8\n",
        "- torch.int16\n",
        "- torch.int32\n",
        "- torch.int64\n",
        "- torch.half\n",
        "- torch.float\n",
        "- torch.double\n",
        "- torch.bfloat"
      ],
      "metadata": {
        "id": "ILU6FdpotXfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros(5, 3)\n",
        "print(z)\n",
        "print(z.dtype) # Note default dtype is float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZIRpwzqDZ5i",
        "outputId": "a9f743ce-799e-4c90-f57d-43c6109dcf3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.ones((5, 3), dtype=torch.int16) # Assigning a dtype\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRLunOFGOJY",
        "outputId": "c17af69d-a3fd-46de-df01-fe440d1f5f6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2, 3), dtype=torch.int16)\n",
        "print(a)\n",
        "\n",
        "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
        "print(b)\n",
        "\n",
        "c = b.to(torch.int32)  # Changing the dtype of a tensor\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myXA5LSRtRwN",
        "outputId": "8d0a0525-1222-45c0-d36a-eb39fb27325b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n",
            "tensor([[ 8.2841,  9.0277, 14.0101],\n",
            "        [17.8955, 12.4802,  5.6579]], dtype=torch.float64)\n",
            "tensor([[ 8,  9, 14],\n",
            "        [17, 12,  5]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1729)\n",
        "r1 = torch.rand(2, 2)\n",
        "print('A random tensor:')\n",
        "print(r1)\n",
        "\n",
        "r2 = torch.rand(2, 2)\n",
        "print('\\nA different random tensor:')\n",
        "print(r2) # new values\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "r3 = torch.rand(2, 2)\n",
        "print('\\nShould match r1:')\n",
        "print(r3) # repeats values of r1 because of re-seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_xC460VGtKY",
        "outputId": "9b184bb9-fd2a-437b-e9aa-cf5004936526"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A random tensor:\n",
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n",
            "\n",
            "A different random tensor:\n",
            "tensor([[0.4216, 0.0691],\n",
            "        [0.2332, 0.4047]])\n",
            "\n",
            "Should match r1:\n",
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(2, 3)\n",
        "print(ones)\n",
        "\n",
        "twos = torch.ones(2, 3) * 2 # every element is multiplied by 2\n",
        "print(twos)\n",
        "\n",
        "threes = ones + twos       # addition allowed because shapes are similar\n",
        "print(threes)              # tensors are added element-wise\n",
        "print(threes.shape)        # this has the same dimensions as input tensors\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obx3kMr5Glqw",
        "outputId": "7b38d51a-92a7-4852-fcac-7a65ce119f86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Shapes\n",
        "Often, when you’re performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the torch.*_like() methods:"
      ],
      "metadata": {
        "id": "mGTUlBo_rYVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 2, 3)  #Creates an empty tensor of the given shape\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "empty_like_x = torch.empty_like(x) # Creates an uninitialized tensor of the given shape(means allocating memory for a tensor without initializing its values.)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)\n",
        "\n",
        "zeros_like_x = torch.zeros_like(x) # Creates a tensor of zeros with the same shape as x.\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)\n",
        "\n",
        "ones_like_x = torch.ones_like(x) #Creates a tensor of ones with the same shape as x.\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)\n",
        "\n",
        "rand_like_x = torch.rand_like(x) #Creates a tensor of random values with the same shape as x.\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb5y97KTrXfa",
        "outputId": "40464b55-96ec-4da7-ffab-ff0afdfdb491"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-1.1010e-09,  3.2747e-41, -1.0954e-09],\n",
            "         [ 3.2747e-41,  8.9683e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.1210e-43,  0.0000e+00, -2.8860e-07],\n",
            "         [ 7.0065e-45,  3.3661e-05,  4.4324e-41]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[ 1.1231e+13,  4.4324e-41,  1.1231e+13],\n",
            "         [ 4.4324e-41,  0.0000e+00,  1.1755e-38]],\n",
            "\n",
            "        [[-1.0718e-12,  3.2747e-41,  2.0000e+00],\n",
            "         [ 0.0000e+00, -1.1011e-09,  3.2747e-41]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.4216, 0.0691, 0.2332],\n",
            "         [0.4047, 0.2162, 0.9927]],\n",
            "\n",
            "        [[0.4128, 0.5938, 0.6128],\n",
            "         [0.1519, 0.0453, 0.5035]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some other ways to create a tensor\n",
        "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
        "print(some_constants)\n",
        "\n",
        "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
        "print(some_integers)\n",
        "\n",
        "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
        "print(more_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvb2TU5wtBTv",
        "outputId": "044a0c96-32a8-4645-9d7f-0ae7a6da77d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.1416, 2.7183],\n",
            "        [1.6180, 0.0073]])\n",
            "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
            "tensor([[2, 4, 6],\n",
            "        [3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.rand(2, 2)) #by Default torch.rand() has an interval of (0,1]\n",
        "\n",
        "# to change the interval\n",
        "a = 5  # lower bound\n",
        "b = 10 # upper bound\n",
        "a + (b - a) * torch.rand(2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onJp7Zq2HjKi",
        "outputId": "77006fd1-f97c-40ec-f03b-ee4145146c22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9978, 0.3884],\n",
            "        [0.6929, 0.1703]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.6922, 7.3795],\n",
              "        [8.7404, 5.1806]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = (torch.rand(2, 2) - 0.5) * 2 # values between -1 and 1\n",
        "print('A random matrix, r:')\n",
        "print(r)\n",
        "\n",
        "# Common mathematical operations are supported:\n",
        "print('\\nAbsolute value of r:')\n",
        "print(torch.abs(r))\n",
        "\n",
        "# ...as are trigonometric functions:\n",
        "print('\\nInverse sine of r:')\n",
        "print(torch.asin(r))\n",
        "\n",
        "# ...and linear algebra operations like determinant and singular value decomposition\n",
        "print('\\nDeterminant of r:')\n",
        "print(torch.det(r))\n",
        "print('\\nSingular value decomposition of r:')\n",
        "print(torch.svd(r))\n",
        "\n",
        "# ...and statistical and aggregate operations:\n",
        "print('\\nAverage and standard deviation of r:')\n",
        "print(torch.std_mean(r))\n",
        "print('\\nMaximum value of r:')\n",
        "print(torch.max(r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4QEDUVKHMHX",
        "outputId": "bc5fd1a7-48f5-4246-cfef-ccbc9fa1b9e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A random matrix, r:\n",
            "tensor([[ 0.0124,  0.6939],\n",
            "        [-0.4823, -0.4587]])\n",
            "\n",
            "Absolute value of r:\n",
            "tensor([[0.0124, 0.6939],\n",
            "        [0.4823, 0.4587]])\n",
            "\n",
            "Inverse sine of r:\n",
            "tensor([[ 0.0124,  0.7669],\n",
            "        [-0.5033, -0.4765]])\n",
            "\n",
            "Determinant of r:\n",
            "tensor(0.3290)\n",
            "\n",
            "Singular value decomposition of r:\n",
            "torch.return_types.svd(\n",
            "U=tensor([[ 0.7278, -0.6858],\n",
            "        [-0.6858, -0.7278]]),\n",
            "S=tensor([0.8872, 0.3708]),\n",
            "V=tensor([[ 0.3830,  0.9237],\n",
            "        [ 0.9237, -0.3830]]))\n",
            "\n",
            "Average and standard deviation of r:\n",
            "(tensor(0.5510), tensor(-0.0587))\n",
            "\n",
            "Maximum value of r:\n",
            "tensor(0.6939)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math & Logic with PyTorch Tensors"
      ],
      "metadata": {
        "id": "fyQcJWxQudHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With Scalars\n",
        "# Arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are distributed over every element of the tensor.\n",
        "ones = torch.zeros(2, 2) + 1\n",
        "twos = torch.ones(2, 2) * 2\n",
        "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
        "fours = twos ** 2\n",
        "sqrt2s = twos ** 0.5\n",
        "\n",
        "print(ones)\n",
        "print(twos)\n",
        "print(threes)\n",
        "print(fours)\n",
        "print(sqrt2s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-mrOuX1ubQV",
        "outputId": "fd9d17b5-e712-4759-9f4b-97c0e980e1df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "tensor([[4., 4.],\n",
            "        [4., 4.]])\n",
            "tensor([[1.4142, 1.4142],\n",
            "        [1.4142, 1.4142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For operations between two tensors, make sure the shapes are identical\n",
        "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
        "print(powers2)\n",
        "\n",
        "fives = ones + fours\n",
        "print(fives)\n",
        "\n",
        "dozens = threes * fours\n",
        "print(dozens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob9ODwiEubM7",
        "outputId": "151b4375-547c-4fa3-aa17-8bc040dc1919"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.],\n",
            "        [ 8., 16.]])\n",
            "tensor([[5., 5.],\n",
            "        [5., 5.]])\n",
            "tensor([[12., 12.],\n",
            "        [12., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Broadcasting\n",
        "Broadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example above, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n",
        "\n",
        "\n",
        "\n",
        "The rules for broadcasting are:\n",
        "\n",
        "- Each tensor must have at least one dimension - no empty tensors.\n",
        "- Comparing the dimension sizes of the two tensors, going from last to first:\n",
        "  - Each dimension must be equal, or\n",
        "  - One of the dimensions must be of size 1, or\n",
        "  - The dimension does not exist in one of the tensors\n",
        "  - Tensors of identical shape, of course, are trivially “broadcastable”"
      ],
      "metadata": {
        "id": "1QNDwa4UwEcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2, 4) * (1, 4) example above returned a tensor of shape (2, 4).\n",
        "\n",
        "rand = torch.rand(2, 4)\n",
        "doubled = rand * (torch.ones(1, 4) * 2)\n",
        "\n",
        "print(rand)\n",
        "print(doubled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52UE27GqubJz",
        "outputId": "fc89accd-fb08-4afe-f4db-afa4aece782d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4115, 0.6839, 0.0703, 0.5105],\n",
            "        [0.9451, 0.2359, 0.1979, 0.3327]])\n",
            "tensor([[0.8230, 1.3677, 0.1405, 1.0210],\n",
            "        [1.8901, 0.4717, 0.3959, 0.6655]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets explore some more examples\n",
        "a =  torch.ones(4, 3, 2)\n",
        "\n",
        "print('Example 1')\n",
        "rand1 = torch.rand(   3, 2)\n",
        "print(rand1)\n",
        "b = a * rand1 # 3rd & 2nd dims identical to a, dim 1 absent\n",
        "print(b)\n",
        "\n",
        "print('Example 2')\n",
        "rand2 = torch.rand(   3, 1)\n",
        "print(rand2)\n",
        "c = a * rand2 # 3rd dim = 1, 2nd dim identical to a\n",
        "print(c)\n",
        "\n",
        "print('Example 3')\n",
        "rand3 = torch.rand(   1, 2)\n",
        "print(rand3)\n",
        "d = a * rand3 # 3rd dim identical to a, 2nd dim = 1\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL8JCATMua2r",
        "outputId": "d7c5750a-cff3-4689-875e-9af05965be44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1\n",
            "tensor([[0.6146, 0.5999],\n",
            "        [0.5013, 0.9397],\n",
            "        [0.8656, 0.5207]])\n",
            "tensor([[[0.6146, 0.5999],\n",
            "         [0.5013, 0.9397],\n",
            "         [0.8656, 0.5207]],\n",
            "\n",
            "        [[0.6146, 0.5999],\n",
            "         [0.5013, 0.9397],\n",
            "         [0.8656, 0.5207]],\n",
            "\n",
            "        [[0.6146, 0.5999],\n",
            "         [0.5013, 0.9397],\n",
            "         [0.8656, 0.5207]],\n",
            "\n",
            "        [[0.6146, 0.5999],\n",
            "         [0.5013, 0.9397],\n",
            "         [0.8656, 0.5207]]])\n",
            "Example 2\n",
            "tensor([[0.6865],\n",
            "        [0.3614],\n",
            "        [0.6493]])\n",
            "tensor([[[0.6865, 0.6865],\n",
            "         [0.3614, 0.3614],\n",
            "         [0.6493, 0.6493]],\n",
            "\n",
            "        [[0.6865, 0.6865],\n",
            "         [0.3614, 0.3614],\n",
            "         [0.6493, 0.6493]],\n",
            "\n",
            "        [[0.6865, 0.6865],\n",
            "         [0.3614, 0.3614],\n",
            "         [0.6493, 0.6493]],\n",
            "\n",
            "        [[0.6865, 0.6865],\n",
            "         [0.3614, 0.3614],\n",
            "         [0.6493, 0.6493]]])\n",
            "Example 3\n",
            "tensor([[0.2633, 0.4762]])\n",
            "tensor([[[0.2633, 0.4762],\n",
            "         [0.2633, 0.4762],\n",
            "         [0.2633, 0.4762]],\n",
            "\n",
            "        [[0.2633, 0.4762],\n",
            "         [0.2633, 0.4762],\n",
            "         [0.2633, 0.4762]],\n",
            "\n",
            "        [[0.2633, 0.4762],\n",
            "         [0.2633, 0.4762],\n",
            "         [0.2633, 0.4762]],\n",
            "\n",
            "        [[0.2633, 0.4762],\n",
            "         [0.2633, 0.4762],\n",
            "         [0.2633, 0.4762]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some common functions with tensors\n",
        "\n",
        "import math\n",
        "\n",
        "# common functions\n",
        "a = torch.rand(2, 4) * 2 - 1\n",
        "print('Common functions:')\n",
        "print(torch.abs(a))\n",
        "print(torch.ceil(a))\n",
        "print(torch.floor(a))\n",
        "print(torch.clamp(a, -0.5, 0.5))\n",
        "\n",
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "sines = torch.sin(angles)\n",
        "inverses = torch.asin(sines)\n",
        "print('\\nSine and arcsine:')\n",
        "print(angles)\n",
        "print(sines)\n",
        "print(inverses)\n",
        "\n",
        "# bitwise operations\n",
        "print('\\nBitwise XOR:')\n",
        "b = torch.tensor([1, 5, 11])\n",
        "c = torch.tensor([2, 7, 10])\n",
        "print(torch.bitwise_xor(b, c))\n",
        "\n",
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool\n",
        "\n",
        "# reductions:\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
        "\n",
        "# vector and linear algebra operations\n",
        "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
        "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
        "m1 = torch.rand(2, 2)                   # random matrix\n",
        "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
        "\n",
        "print('\\nVectors & Matrices:')\n",
        "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
        "print(m1)\n",
        "m3 = torch.matmul(m1, m2)\n",
        "print(m3)                  # 3 times m1\n",
        "print(torch.svd(m3))       # singular value decomposition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhnM_utgnH7z",
        "outputId": "d714c63d-b34a-42aa-91d9-b3650b4253ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common functions:\n",
            "tensor([[0.8904, 0.5951, 0.1461, 0.4382],\n",
            "        [0.1866, 0.4602, 0.2551, 0.4715]])\n",
            "tensor([[-0., -0., 1., 1.],\n",
            "        [-0., 1., 1., 1.]])\n",
            "tensor([[-1., -1.,  0.,  0.],\n",
            "        [-1.,  0.,  0.,  0.]])\n",
            "tensor([[-0.5000, -0.5000,  0.1461,  0.4382],\n",
            "        [-0.1866,  0.4602,  0.2551,  0.4715]])\n",
            "\n",
            "Sine and arcsine:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n",
            "\n",
            "Bitwise XOR:\n",
            "tensor([3, 2, 1])\n",
            "\n",
            "Broadcasted, element-wise equality comparison:\n",
            "tensor([[ True, False],\n",
            "        [False, False]])\n",
            "\n",
            "Reduction ops:\n",
            "tensor(4.)\n",
            "4.0\n",
            "tensor(2.5000)\n",
            "tensor(1.2910)\n",
            "tensor(24.)\n",
            "tensor([1, 2])\n",
            "\n",
            "Vectors & Matrices:\n",
            "tensor([ 0.,  0., -1.])\n",
            "tensor([[0.0381, 0.2138],\n",
            "        [0.5395, 0.3686]])\n",
            "tensor([[0.1143, 0.6414],\n",
            "        [1.6186, 1.1057]])\n",
            "torch.return_types.svd(\n",
            "U=tensor([[-0.2387, -0.9711],\n",
            "        [-0.9711,  0.2387]]),\n",
            "S=tensor([2.0155, 0.4524]),\n",
            "V=tensor([[-0.7934,  0.6087],\n",
            "        [-0.6087, -0.7934]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying Tensors\n",
        "a = torch.ones(2, 2)\n",
        "b = a.clone()"
      ],
      "metadata": {
        "id": "25GoOcZeyLYv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving to GPU\n",
        "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing.) So far, everything we’ve done has been on CPU. How do we move to the faster hardware?\n",
        "\n",
        "First, we should check whether a GPU is available, with the ```is_available()``` method."
      ],
      "metadata": {
        "id": "oE_vRjg-yyDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SckPYWu2yLVW",
        "outputId": "3284a578-671f-416e-dd47-2c0472466339"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "print('Device: {}'.format(my_device))\n",
        "\n",
        "x = torch.rand(2, 2, device=my_device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E67iNTI879rZ",
        "outputId": "638d933a-18e1-454f-c78c-58c41c9d5c17"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "tensor([[0.3344, 0.2640],\n",
            "        [0.2119, 0.0582]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors"
      ],
      "metadata": {
        "id": "uSj6jah27-be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing dimensions of Tensor\n",
        "a = torch.rand(3, 226, 226)\n",
        "b = a.unsqueeze(0)  # a.unsqueeze(0): Adds a new dimension at the specified position (0 in this case).\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RhIdpWXyLSU",
        "outputId": "d831be5e-163b-4b45-c469-a3ab1e000548"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1, 20)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "b = a.squeeze(0) #Removes a dimension at the specified position (0 in this case). Since the original tensor a had a size of 1 along this dimension, it is removed.\n",
        "print(b.shape)\n",
        "print(b)\n",
        "\n",
        "c = torch.rand(2, 2)\n",
        "print(c.shape)\n",
        "\n",
        "d = c.squeeze(0) # Attempts to remove a dimension at position 0. However, since the original tensor c does not have a size-1 dimension along this axis, the tensor remains unchanged.\n",
        "print(d.shape)\n",
        "\n",
        "# In summary, the squeeze method is used to remove dimensions with size 1. If the specified dimension has size greater than 1 or does not exist, the tensor remains unchanged."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_bQ8VMqyLPu",
        "outputId": "17d15fa2-a0ac-4279-8810-93da946da75b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.8394, 0.8083, 0.5408, 0.2576, 0.5258, 0.5329, 0.5899, 0.4933, 0.3665,\n",
            "         0.1891, 0.9775, 0.7781, 0.0915, 0.4627, 0.7947, 0.7478, 0.8827, 0.6334,\n",
            "         0.3902, 0.3691]])\n",
            "torch.Size([20])\n",
            "tensor([0.8394, 0.8083, 0.5408, 0.2576, 0.5258, 0.5329, 0.5899, 0.4933, 0.3665,\n",
            "        0.1891, 0.9775, 0.7781, 0.0915, 0.4627, 0.7947, 0.7478, 0.8827, 0.6334,\n",
            "        0.3902, 0.3691])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping a tensor\n",
        "output3d = torch.rand(6, 20, 20)\n",
        "print(output3d.shape)\n",
        "\n",
        "# Note: The dimensions you request yield the same number of elements as the input tensor\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(input1d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIogSZdnyLNc",
        "outputId": "3fafb13b-77c7-4364-d365-866416b5f543"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 20, 20])\n",
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting numpy to tensor\n",
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2, 3))\n",
        "print(numpy_array)\n",
        "\n",
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "print(pytorch_tensor)\n",
        "\n",
        "# Converting tensors to numpy\n",
        "pytorch_rand = torch.rand(2, 3)\n",
        "print(pytorch_rand)\n",
        "\n",
        "numpy_rand = pytorch_rand.numpy()\n",
        "print(numpy_rand)\n",
        "\n",
        "# Note: Since both numpy array and tensor will share the same memory, manipulation/change in any one will lead to manipulation/change in other"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V8SweQpyJ-Y",
        "outputId": "e3c4879a-fdf4-4741-86d4-04c74a22a95e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[0.1923, 0.2480, 0.1941],\n",
            "        [0.2385, 0.0628, 0.6008]])\n",
            "[[0.19231671 0.2479614  0.1940757 ]\n",
            " [0.23848575 0.06282878 0.6008167 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model buidling using Torch"
      ],
      "metadata": {
        "id": "CAfaYBiWItUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data set and DataLoader"
      ],
      "metadata": {
        "id": "SI6vauySBoaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# For converting the inputs into required format for torch. First convert the inputs to tensors then normalize it\n",
        "\n",
        "# But before loading the dataset and setting up means and std for transforms use the below code for calculating them\n",
        "# Assuming you have a CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
        "\n",
        "# Calculate mean and std for each channel\n",
        "mean = tuple(trainset.data.mean(axis=(0, 1, 2)) / 255.0)\n",
        "std = tuple(trainset.data.std(axis=(0, 1, 2)) / 255.0)\n",
        "\n",
        "print(mean)\n",
        "print(std)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])  #  (means), (std)\n",
        "\n",
        "# loading a inbuilt dataset CIFAR10 using the transformation\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# trainset: This is assumed to be a PyTorch dataset\n",
        "# batch_size=4: This parameter determines the number of samples in each batch.\n",
        "#               During training, the model's parameters are updated based on the average loss computed over this batch.\n",
        "\n",
        "# shuffle=True: This parameter indicates whether the data should be shuffled at the beginning of each epoch.\n",
        "# Shuffling helps in randomizing the order of samples within each batch, preventing the model from learning patterns based on the order of the data.\n",
        "\n",
        "# num_workers=2: This parameter specifies the number of worker processes to use for data loading.\n",
        "# Multiple workers can load batches in parallel, improving data loading efficiency. The value of num_workers is often set based on the available CPU cores.\n",
        "\n",
        "\n",
        "# Repeat the same for test dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWr03QTSNKeV",
        "outputId": "9fd3adea-2e73-4334-9a69-7cac18dfeaab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12891696.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "(0.49139967861519607, 0.48215840839460783, 0.44653091444546567)\n",
            "(0.24703223246328176, 0.24348512800005648, 0.26158784172796473)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "sIwXm94ANKUX",
        "outputId": "815a607b-bb1c-4365-b8cf-dc3e0c71bc8c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " bird  ship plane  bird\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The input image is of 32x32 size with 3 channels\n",
        "\n",
        "# So base on the architecture the first convolution layer should have 3 filters\n",
        "# The output from first layer will have size of 28x28 then with max pooling with filter of 2 and stride 2 gives output of size 14x14\n",
        "# The output from second layer will have size of 10x10 then with max pooling with filter of 2 and stride 2 gives output of size 5x5\n",
        "# For the feedforward network ahead we will have to flatten it using these dimensions 16 * 5 * 5\n",
        "# then it followed by a fully connnected network\n",
        "\n",
        "\n",
        "# Loading relevant libraries\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Setting up a class for neural network architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self): #Set up the operations you want to perform in the Neural Network\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,6,5) #(InputChannel, OutputChannels, SizeofFilter)\n",
        "        self.pool = nn.MaxPool2d(2,2) # formats (2,2) (filter size, stride)   #Other format ((2,2), stride = 2)\n",
        "        self.conv2 = nn.Conv2d(6,16,5) #(InputChannel, OutputChannels, SizeofFilter)\n",
        "        self.fc1 = nn.Linear(16*5*5,120) #(Inputs, outputs)\n",
        "        self.fc2 = nn.Linear(120,84) #(Inputs, outputs)\n",
        "        self.fc3 = nn.Linear(84,10) #(Inputs, outputs)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5) # Reshapes the output tensor into a 1D tensor for input to the fully connected layers.\n",
        "        x = self.fc1(x)\n",
        "        x= F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x= F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        #x= F.softmax(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "EyLDEPKvNKRN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Setting up Gradient descent optimizer and learning rate\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "d8VHBEI9Oa-F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times (In other words, setting up the epochs)\n",
        "\n",
        "    running_loss = 0.0 # To calculate the loss for a batch later\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data #Splitting features and labels\n",
        "\n",
        "        # Resetting the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)   # Forward pass\n",
        "        loss = criterion(outputs, labels) #Loss calculation\n",
        "        loss.backward() # Backpropogation\n",
        "        optimizer.step() # to perform a parameter update based on the computed gradients.\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches #Setting up the batch sizes\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmL8swGqOa63",
        "outputId": "08e4564e-9b9e-4463-af58-ee70f8a5063b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.085\n",
            "[1,  4000] loss: 1.731\n",
            "[1,  6000] loss: 1.586\n",
            "[1,  8000] loss: 1.506\n",
            "[1, 10000] loss: 1.477\n",
            "[1, 12000] loss: 1.431\n",
            "[2,  2000] loss: 1.351\n",
            "[2,  4000] loss: 1.331\n",
            "[2,  6000] loss: 1.321\n",
            "[2,  8000] loss: 1.305\n",
            "[2, 10000] loss: 1.294\n",
            "[2, 12000] loss: 1.240\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Predicting on the test set and calculating the accuracy\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE__awPUOa28",
        "outputId": "b54c454b-f3e1-48f7-8bc1-2b11f8afeee1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 56 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23B3X3nMOayz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}